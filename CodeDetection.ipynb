{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a28bf702",
   "metadata": {},
   "source": [
    "## Dataset Preprocessing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2e917939",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "def csv_to_jsonl_split(input_path: str, \n",
    "                       output_human_path: str, \n",
    "                       output_llm_path: str):\n",
    "    '''\n",
    "    \n",
    "    '''\n",
    "    ds = pd.read_csv(input_path)\n",
    "\n",
    "    # colonna da tenere\n",
    "    CODE_CONLUMN = \"cleared_code\"       # <-- la feature che vuoi salvare\n",
    "    SPLIT = \"LLM\"        # <-- la colonna che decide dove va il sample\n",
    "    target = \"Human\"              # <-- valore discriminante\n",
    "\n",
    "    ds = pd.read_csv(input_path)\n",
    "\n",
    "    # split dataset\n",
    "    dataset_match = ds[ds[SPLIT] == target]\n",
    "    dataset_other = ds[ds[SPLIT] != target]\n",
    "\n",
    "    # salva human.jsonl\n",
    "    with open(output_human_path, \"w\", encoding=\"utf-8\") as f:\n",
    "        for _, row in dataset_match.iterrows():\n",
    "            f.write(json.dumps(row.to_dict(), ensure_ascii=False) + \"\\n\")\n",
    "\n",
    "    # salva llm.jsonl\n",
    "    with open(output_llm_path, \"w\", encoding=\"utf-8\") as f:\n",
    "        for _, row in dataset_other.iterrows():\n",
    "            f.write(json.dumps(row.to_dict(), ensure_ascii=False) + \"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6c4a0675",
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_PATH = './Dataset/AIGCodeSet.csv'\n",
    "HUMAN_PATH = \"./Methods/Code_detection/results/AIGCodeSethuman.json\"\n",
    "LLM_PATH = \"./Methods/Code_detection/results/AIGCodeSetllm.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cd4a920e",
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_to_jsonl_split(input_path = INPUT_PATH, \n",
    "                    output_human_path = HUMAN_PATH, \n",
    "                    output_llm_path = LLM_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f52cc5e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "import torch, json\n",
    "import random, os\n",
    "from Methods.Code_detection.utils_batch import InfillingModel\n",
    "import tqdm\n",
    "\n",
    "def run_fill_in_the_middle(\n",
    "    input_path,                # es: \"gpt4_python_codecontest.jsonl\"\n",
    "    output_path=\"./Methods/Code_detection/results/fim.josnl\", \n",
    "    batch_size=20,\n",
    "    mask_lines=1,\n",
    "    model_name=\"facebook/incoder-6B\",\n",
    "    code_lable = 'cleared_code'\n",
    "):\n",
    "    \"\"\"\n",
    "    input_path: must be a .jsonl\n",
    "    Esegue la perturbazione FIM su un dataset JSONL con campo 'code_lable'.\n",
    "    Salva un nuovo JSONL con campo 'fill_in_middle_gold'.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Config GPU\n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "    # half precision solo per incoder-6B\n",
    "    half = True if model_name == \"facebook/incoder-6B\" else False\n",
    "    \n",
    "    infilling_model = InfillingModel(model_name=model_name, cuda=True, half=half, device=device, quantization = \"nf4\")\n",
    "\n",
    "    # upload dataset\n",
    "    with open(input_path, 'r', encoding=\"utf-8\") as f:\n",
    "        dataset = [json.loads(line) for line in f.readlines()]\n",
    "\n",
    "    # support functions\n",
    "    def find_all(substring, string):\n",
    "        start = 0\n",
    "        while True:\n",
    "            start = string.find(substring, start)\n",
    "            if start == -1: return\n",
    "            yield start\n",
    "            start += len(substring)\n",
    "\n",
    "    def mask_code(parsed_code, mask_lines=mask_lines):\n",
    "        for _ in range(mask_lines):\n",
    "            positions = list(find_all(substring='\\n', string=parsed_code))\n",
    "            if positions == []:\n",
    "                positions = list(find_all(substring=':', string=parsed_code))\n",
    "            if len(positions) < 2:\n",
    "                continue\n",
    "            mask_start = random.choice(range(len(positions)-1))\n",
    "            mask_start_position = positions[mask_start]\n",
    "            mask_end_position = positions[mask_start+1]\n",
    "            parsed_code = parsed_code[:mask_start_position] + '<insert>' + parsed_code[mask_end_position:]\n",
    "        return parsed_code\n",
    "\n",
    "    def norm_inserts_num(parsed_code_norm):\n",
    "        max_num = 0\n",
    "        for i, x in enumerate(parsed_code_norm):\n",
    "            if len(list(find_all('<insert>', x))) > max_num:\n",
    "                max_num = len(list(find_all('<insert>', x)))\n",
    "                id = i\n",
    "\n",
    "        new_res = []\n",
    "        for x in parsed_code_norm:\n",
    "            if len(list(find_all('<insert>', x))) < max_num:\n",
    "                new_res.append(parsed_code_norm[id])\n",
    "            else:\n",
    "                new_res.append(x)\n",
    "        return new_res\n",
    "    ## end support function\n",
    "    \n",
    "\n",
    "    # output check\n",
    "    if os.path.exists(output_path):\n",
    "        with open(output_path, 'r') as f:\n",
    "            finished = [json.loads(line) for line in f.readlines()]\n",
    "        dataset = dataset[len(finished):]\n",
    "\n",
    "\n",
    "    # MAIN CYCLE\n",
    "    for idx, ins in tqdm.tqdm(enumerate(dataset), total=len(dataset)):\n",
    "        code_lable_all = []\n",
    "        if len(ins[code_lable]) < 2500:\n",
    "            for _ in range(batch_size):\n",
    "                gold_codes_masked = mask_code(ins[code_lable], mask_lines=mask_lines)\n",
    "                code_lable_all.append(gold_codes_masked[:2500])\n",
    "\n",
    "            code_lable_all = norm_inserts_num(code_lable_all)\n",
    "            parts_batch = [example.split(\"<insert>\") for example in code_lable_all]\n",
    "            fill_in_middle_gold = infilling_model.batched_infill(\n",
    "                parts_batch, max_to_generate=16*mask_lines, temperature=0.7\n",
    "            )\n",
    "            ins['fill_in_middle_gold'] = fill_in_middle_gold\n",
    "        else:\n",
    "            ins['fill_in_middle_gold'] = ['token exceeds 2500']\n",
    "\n",
    "        with open(output_path, 'a') as f:\n",
    "            f.write(json.dumps(ins) + '\\n')\n",
    "    \n",
    "\n",
    "    return output_path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b642e4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading model\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "625738ff999c4c4b86d8a5a6563f0c6f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/26.6G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading complete\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'./Methods/Code_detection/results/HUMANfim.josnl'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_fill_in_the_middle(\n",
    "    input_path = HUMAN_PATH,\n",
    "    output_path=\"./Methods/Code_detection/results/HUMANfim.jsonl\", \n",
    "    batch_size=20,\n",
    "    mask_lines=1,\n",
    "    model_name=\"facebook/incoder-6B\",\n",
    "    code_lable = 'cleared_code'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f32c71c",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_fill_in_the_middle(\n",
    "    input_path = LLM_PATH,\n",
    "    output_path=\"./Methods/Code_detection/results/LLMfim.jsonl\", \n",
    "    batch_size=2,\n",
    "    mask_lines=1,\n",
    "    model_name=\"facebook/incoder-6B\",\n",
    "    code_lable = 'cleared_code'\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
